{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Breach Transformation using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to setup/start a local postgres sql server and transform the data breach data and load it to the postgres database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and start Postgresql (Only for mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Install PostgreSQL with Homebrew\n",
    "install_postgres_command = \"brew install postgresql@15\"\n",
    "subprocess.run(install_postgres_command, shell=True)\n",
    "\n",
    "# Start PostgreSQL service\n",
    "start_postgres_command = \"brew services start postgresql\"\n",
    "subprocess.run(start_postgres_command, shell=True)\n",
    "\n",
    "# Create postgres user\n",
    "user_create_command = \"/opt/homebrew/bin/createuser -s postgres\"\n",
    "subprocess.run(user_create_command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract (from CSV), Transform (Using Python) and Load (Insert data to postgres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform is implemented using the `Pandas` and sql connections are using `sqlalchemy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from the CSV and load it into a Pandas DataFrame. The data has two columns Serial a duplicate column with the serial numbers and Sources which is not relevant for the use case. So we are dropping those two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_breaches.csv')\n",
    "df = df.drop(columns=['Serial', 'Sources'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once data is in the DataFrame, now the `Records` column in the data has both numerics and strings. Whereas the strings are arbitrary unknown values. So to cleanse and load the data into postgres, we will check if the rows in `records` are numeric if not make it a `NaN` value.\n",
    "\n",
    "Once all the strings are in `NaN` type, we then cast the column to an `int` type and fill the `NaN` as `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Records'] = pd.to_numeric(df['Records'], errors='coerce')\n",
    "df = df.fillna(0).astype({'Records': 'int'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let move on to the `Year` column, it has some inconsistencies in the some rows where as two years split with either `-` or `and` ex: `2014-2015` or `2014 and 2015`. Here we can use the [`iterrow`](https://pandas.pydata.org/docs/user_guide/basics.html#iteration) to split the insconsistent year rows into two but it is not suggested by Pandas does not suggest using it. So we did a `split` on the whole column based on the string as the column is already in string format and `explode`` it back to the DataFrame with re-indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split rows with \"-\" string\n",
    "df['Year'] = df['Year'].str.split('-')\n",
    "df = df.explode('Year', ignore_index=True)\n",
    "\n",
    "# Split the rows with \" and \" into two rows\n",
    "df['Year'] = df['Year'].str.split(' and ')\n",
    "df = df.explode('Year', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we check the columns types both `Records` and `Year` should be an `int` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into the postgresql server using `sqlalchemy` package and create a engine. We used `if_exists='replace'` so that data will be replaced instead of failing while loading it and not load the index which is set to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_url = \"postgresql://postgres@localhost/breach\"\n",
    "engine = create_engine(db_url)\n",
    "df.to_sql('cleansed', engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
